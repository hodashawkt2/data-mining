# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15L-hEkefunptvgH1VfWXoHXXoYdLXOR7

ðŸ”¹ Step 1: Verify the Uploaded File
"""

import os

# List files in the current working directory
print(os.listdir())

""" Step 2: Read the JSON File"""

import json

file_name = "TBD3.json"  # Ensure the file extension is correct!

# Open and load the JSON file
with open("TBD3.json", 'r', encoding='utf-8') as f:
    data = json.load(f)

print("âœ… File loaded successfully!")
print("ðŸ“‚ Sample data:", data[:2])  # Display first 2 records for verification

"""ðŸ“Š Step 3: Convert JSON to a Pandas DataFrame


The Apriori algorithm requires structured data. Letâ€™s convert the JSON file into a Pandas DataFrame.
"""

import pandas as pd

# Convert JSON to DataFrame
df = pd.DataFrame(data)


print("âœ… Data converted to DataFrame!")
print(df.head())  # Show the first few rows

"""Step 4: Preprocess the Data

Apriori works on transactions, so we need to process the data correctly.
"""

# Assuming the dataset contains a column with lists of items bought together
# Adjust column names based on my JSON structure!
df['items'] = df['items'].apply(lambda x: x if isinstance(x, list) else [])

# Display processed transactions
transactions = df['items'].tolist()
print("âœ… Transactions ready for Apriori!")
print(transactions[:3])  # Display first 3 transactions

"""ðŸ“ˆ Step 5: Apply the Apriori Algorithm

using the MLxtend library to apply the Apriori algorithm.
"""

from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder

# Convert transactions to the required format
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_encoded = pd.DataFrame(te_ary, columns=te.columns_)

# Apply Apriori algorithm
min_support = 0.01
frequent_itemsets = apriori(df_encoded, min_support=min_support, use_colnames=True)

print("âœ… Frequent itemsets found!")
print(frequent_itemsets)

"""ðŸ“Œ Step 6: Generate Association Rules

generating association rules based on the frequent itemsets.
"""

# Generate association rules
min_confidence = 0.8  # Adjust confidence threshold as needed
rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)

print("âœ… Association Rules Generated!")
print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])

filtered_rules = rules[rules['lift'] > 1.5]
print("âœ… Filtered Strong Rules!")
print(filtered_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])

"""Save the Results to CSV"""

filtered_rules.to_csv("strong_association_rules.csv", index=False)
print("âœ… Rules saved to strong_association_rules.csv!")

from google.colab import drive
drive.mount('/content/drive')